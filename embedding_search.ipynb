{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough example of doing cosine similarity search based on a few known examples of log yards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your local path to the NAIP embeddings data (or a subset/subdirectory of it)\n",
    "root = \"/mnt/c/data/clay_naip/wa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1686840/337654264.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  log_yard_gdf[\"geometry\"] = log_yard_gdf.geometry.centroid\n"
     ]
    }
   ],
   "source": [
    "# Load example log yards\n",
    "log_yard_paths = [\n",
    "    \"/mnt/c/data/clay_naip_results/labels/log_yard_1.gpkg\",\n",
    "    \"/mnt/c/data/clay_naip_results/labels/log_yard_2.gpkg\",\n",
    "    \"/mnt/c/data/clay_naip_results/labels/log_yard_3.gpkg\",\n",
    "]\n",
    "# load with geopandas\n",
    "log_yard_gdfs = []\n",
    "for path in log_yard_paths:\n",
    "    gdf = gpd.read_file(path)\n",
    "    log_yard_gdfs.append(gdf)\n",
    "log_yard_gdf = pd.concat(log_yard_gdfs, ignore_index=True)\n",
    "# convert to points (centroids)\n",
    "log_yard_gdf.crs = \"EPSG:4326\"\n",
    "log_yard_gdf[\"geometry\"] = log_yard_gdf.geometry.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3184/3184 [04:37<00:00, 11.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load all parquet files to get embeddings of log yards and all geometries for visualisation\n",
    "\n",
    "def read_parquet_files(root, intersecting_gdf=None):\n",
    "    \"\"\"\n",
    "    Reads a list of parquet files and processes their geometries and embeddings.\n",
    "    Returns embeddings for rows that intersect with the provided GeoDataFrame.\n",
    "    Returns all geometries in a GeoDataFrame.\n",
    "\n",
    "    Args:\n",
    "        files (list): List of file paths to parquet files.\n",
    "        intersecting_gdf (GeoDataFrame, optional): A GeoDataFrame to check for intersections.\n",
    "            If provided, only geometries and embeddings intersecting with this GeoDataFrame\n",
    "            will be included in the second returned GeoDataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - main_gdf (GeoDataFrame): A GeoDataFrame containing all geometries from the parquet files.\n",
    "            - select_embeddings (GeoDataFrame or None): A GeoDataFrame containing rows with geometries\n",
    "              and embeddings that intersect with the provided GeoDataFrame. Returns None if no\n",
    "              intersecting_gdf is provided or no intersections are found.\n",
    "    \"\"\"\n",
    "\n",
    "    files = []\n",
    "    for root, dirs, filenames in os.walk(root):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".parquet\"):\n",
    "                files.append(os.path.join(root, filename))\n",
    "\n",
    "    geoms = []\n",
    "    select_embeddings = []\n",
    "    for i, file in enumerate(tqdm(files)):\n",
    "\n",
    "        # read the parquet file\n",
    "        df = gpd.read_parquet(file)\n",
    "        # append the geometry and embedding to the lists\n",
    "        geoms.extend(df.geometry.tolist())\n",
    "        if intersecting_gdf is not None:\n",
    "            # check for intersection with the provided gdf\n",
    "            # use sjoin\n",
    "            df.crs = \"EPSG:4326\"\n",
    "            intersecting_rows = gpd.sjoin(\n",
    "                df, intersecting_gdf, how=\"inner\", predicate=\"intersects\"\n",
    "            )\n",
    "            if len(intersecting_rows) > 0:\n",
    "                select_embeddings.append(intersecting_rows)\n",
    "\n",
    "    # return the 2 gdfs\n",
    "    main_gdf = gpd.GeoDataFrame(geometry=geoms, crs=\"EPSG:4326\")\n",
    "    if len(select_embeddings) > 0:\n",
    "        # concatenate the list of dataframes into a single dataframe\n",
    "        select_embeddings = pd.concat(select_embeddings)\n",
    "\n",
    "    return main_gdf, select_embeddings\n",
    "\n",
    "# read the parquet files\n",
    "main_gdf, logyard_embeddings_gdf = read_parquet_files(root, log_yard_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean embedding for log yards\n",
    "# Warning: see Readme - this doesn't work well for many examples!\n",
    "\n",
    "# Define cosine similarity function\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "query_embeddings = logyard_embeddings_gdf.embeddings#.iloc[0].embeddings\n",
    "query_centroid = query_embeddings.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dask pipeline to compute cosine similarity\n",
    "\n",
    "# Function to apply to each row embedding\n",
    "def compute_cos_sim(embedding):\n",
    "    emb_array = np.array(embedding)\n",
    "    return cosine_similarity(emb_array, query_centroid)\n",
    "\n",
    "# Load Dask dataframe from Parquet\n",
    "ddf = dd.read_parquet(root)\n",
    "\n",
    "# Compute cosine similarity lazily\n",
    "ddf_sim = ddf.assign(\n",
    "            cos_sim=ddf[\"embeddings\"].apply(compute_cos_sim, meta=(\"cos_sim\", \"f8\"))\n",
    "            ).drop(columns=[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the computation and convert results to geodataframe\n",
    "\n",
    "result_df = ddf_sim.compute()\n",
    "\n",
    "result_df[\"geometry\"] = result_df[\"geometry\"].apply(shapely.wkb.loads)\n",
    "\n",
    "# Reconstruct GeoDataFrame\n",
    "result_gdf = gpd.GeoDataFrame(result_df, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cosine similiarity rank column\n",
    "# and sort by it\n",
    "result_gdf[\"rank\"] = result_gdf[\"cos_sim\"].rank(ascending=False)\n",
    "result_gdf = result_gdf.sort_values(\"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output\n",
    "output_path = os.path.join(root, \"log_yards_cosinesim_ranked.gpkg\")\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "result_gdf.to_file(output_path, driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "log-embeddings",
   "language": "python",
   "name": "log-embeddings-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
